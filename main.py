# main.py
import os
import logging
from telegram import Update
from telegram.ext import Application, ContextTypes, MessageHandler, filters
import requests
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
PORT = int(os.environ.get("PORT", 8443))

async def full_hf_diagnosis(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ HuggingFace –¥–æ—Å—Ç—É–ø–∞"""
    
    await update.message.reply_text("üîç –ó–∞–ø—É—Å–∫–∞—é –ø–æ–ª–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É HF...")
    
    results = []
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    try:
        response = requests.get(
            "https://huggingface.co/api/whoami",
            headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
            timeout=10
        )
        if response.status_code == 200:
            user_info = response.json()
            results.append(f"‚úÖ –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è: –£—Å–ø–µ—à–Ω–æ")
            results.append(f"   üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_info.get('name')}")
            results.append(f"   üîë –†–æ–ª—å: {user_info.get('role')}")
            results.append(f"   üöÄ Inference API: {user_info.get('canAccessInferenceAPI', False)}")
        else:
            results.append(f"‚ùå –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è: –ù–µ—É–¥–∞—á–∞ (Status: {response.status_code})")
    except Exception as e:
        results.append(f"‚ùå –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è: –û—à–∏–±–∫–∞ - {e}")

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ Inference API
    try:
        response = requests.get(
            "https://api-inference.huggingface.co/models/gpt2",  # –ü—Ä–æ—Å—Ç–∞—è —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å
            headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
            timeout=10
        )
        if response.status_code == 200:
            results.append("‚úÖ Inference API: –î–æ—Å—Ç—É–ø–µ–Ω")
        elif response.status_code == 403:
            results.append("‚ùå Inference API: –ó–∞–ø—Ä–µ—â–µ–Ω–æ (403)")
        elif response.status_code == 404:
            results.append("‚ùå Inference API: –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (404)")
        else:
            results.append(f"‚ùå Inference API: –û—à–∏–±–∫–∞ {response.status_code}")
    except Exception as e:
        results.append(f"‚ùå Inference API: –û—à–∏–±–∫–∞ - {e}")

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Stable Diffusion
    sd_models = [
        "runwayml/stable-diffusion-v1-5",
        "stabilityai/stable-diffusion-2-1",
        "CompVis/stable-diffusion-v1-4"
    ]
    
    results.append("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π Stable Diffusion:")
    
    for model in sd_models:
        try:
            response = requests.post(
                f"https://api-inference.huggingface.co/models/{model}",
                headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
                json={"inputs": "test"},
                timeout=15
            )
            
            if response.status_code == 200:
                results.append(f"  ‚úÖ {model}: –î–æ—Å—Ç—É–ø–Ω–∞")
            elif response.status_code == 402:
                results.append(f"  üí∞ {model}: –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–ª–∞—Ç–∞ (402)")
            elif response.status_code == 403:
                results.append(f"  üö´ {model}: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ (403)")
            elif response.status_code == 404:
                results.append(f"  ‚ùå {model}: –ù–µ –Ω–∞–π–¥–µ–Ω–∞ (404)")
            elif response.status_code == 503:
                results.append(f"  ‚è≥ {model}: –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è (503)")
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—à–∏–±–∫—É
                try:
                    error_data = response.json()
                    error_msg = error_data.get('error', 'Unknown')
                    results.append(f"  ‚ùì {model}: {response.status_code} - {error_msg}")
                except:
                    results.append(f"  ‚ùì {model}: {response.status_code}")
                    
        except Exception as e:
            results.append(f"  üí• {model}: –û—à–∏–±–∫–∞ - {e}")

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ API
    try:
        response = requests.get(
            f"https://huggingface.co/api/models/runwayml/stable-diffusion-v1-5",
            timeout=10
        )
        if response.status_code == 200:
            model_info = response.json()
            results.append(f"\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
            results.append(f"   üì• –ó–∞–≥—Ä—É–∑–∫–∏: {model_info.get('downloads', 'N/A')}")
            results.append(f"   üè∑Ô∏è –õ–∏—Ü–µ–Ω–∑–∏—è: {model_info.get('license', 'N/A')}")
            results.append(f"   ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: {model_info.get('cardData', {}).get('license', 'N/A')}")
    except Exception as e:
        results.append(f"\n‚ùì –ò–Ω—Ñ–æ –æ –º–æ–¥–µ–ª–∏: –û—à–∏–±–∫–∞ - {e}")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    result_text = "\n".join(results)
    await update.message.reply_text(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏:\n{result_text}")

async def check_subscription_status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –ø–æ–¥–ø–∏—Å–∫–∏ HF"""
    await update.message.reply_text("üîç –ü—Ä–æ–≤–µ—Ä—è—é —Å—Ç–∞—Ç—É—Å –ø–æ–¥–ø–∏—Å–∫–∏...")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –∫ –ø–ª–∞—Ç–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏—è–º
        response = requests.get(
            "https://huggingface.co/api/billing/subscription",
            headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
            timeout=10
        )
        
        if response.status_code == 200:
            sub_info = response.json()
            await update.message.reply_text(
                f"üìã –°—Ç–∞—Ç—É—Å –ø–æ–¥–ø–∏—Å–∫–∏:\n"
                f"   üí∞ Plan: {sub_info.get('plan', 'Free')}\n"
                f"   üìä Usage: {sub_info.get('usage', 'N/A')}\n"
                f"   üöÄ Limits: {sub_info.get('limits', 'N/A')}"
            )
        elif response.status_code == 404:
            await update.message.reply_text("‚ùå –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç)")
        else:
            await update.message.reply_text(f"‚ùì –°—Ç–∞—Ç—É—Å –ø–æ–¥–ø–∏—Å–∫–∏: {response.status_code}")
            
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–ø–∏—Å–∫–∏: {e}")

async def test_simple_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–¢–µ—Å—Ç —Å –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª—å—é (–Ω–µ SD)"""
    await update.message.reply_text("üß™ –¢–µ—Å—Ç–∏—Ä—É—é –ø—Ä–æ—Å—Ç—É—é —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å...")
    
    try:
        response = requests.post(
            "https://api-inference.huggingface.co/models/gpt2",
            headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
            json={"inputs": "Hello, how are you?"},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            await update.message.reply_text(f"‚úÖ –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç!\n–û—Ç–≤–µ—Ç: {str(result)[:200]}...")
        else:
            await update.message.reply_text(f"‚ùå –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {response.status_code}")
            
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ë–æ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ HuggingFace\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/diagnose - –ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞\n" 
        "/subscription - –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–ø–∏—Å–∫–∏\n"
        "/test_model - –¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏\n"
        "/generate - –ü–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
    )

async def generate_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"""
    prompt = update.message.text
    user_id = update.effective_user.id
    
    try:
        logger.info(f"User {user_id} requested: {prompt}")
        await update.message.reply_text("üé® –ü—ã—Ç–∞—é—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å...")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø
        response = requests.get(
            "https://huggingface.co/api/whoami",
            headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
            timeout=10
        )
        
        if response.status_code != 200:
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ HF")
            return
            
        user_info = response.json()
        can_access_inference = user_info.get('canAccessInferenceAPI', False)
        
        if not can_access_inference:
            await update.message.reply_text(
                "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ Inference API!\n\n"
                "–†–µ—à–µ–Ω–∏–µ:\n"
                "1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ Settings ‚Üí Billing –Ω–∞ HF\n" 
                "2. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ Inference API\n"
                "3. –í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–∞ –ø—Ä–∏–≤—è–∑–∫–∞ –∫–∞—Ä—Ç—ã"
            )
            return
        
        # –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        response = requests.post(
            "https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5",
            headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
            json={"inputs": prompt},
            timeout=120
        )
        
        logger.info(f"Generation status: {response.status_code}")
        
        if response.status_code == 200:
            from io import BytesIO
            from PIL import Image
            
            image = Image.open(BytesIO(response.content))
            bio = BytesIO()
            bio.name = 'image.png'
            image.save(bio, 'PNG')
            bio.seek(0)
            
            await update.message.reply_photo(photo=bio, caption=f"üé® {prompt}")
            
        elif response.status_code == 402:
            await update.message.reply_text(
                "‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–ª–∞—Ç–∞ –¥–ª—è Stable Diffusion!\n\n"
                "–†–µ—à–µ–Ω–∏–µ:\n" 
                "1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://huggingface.co/settings/billing\n"
                "2. –î–æ–±–∞–≤—å—Ç–µ —Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã\n"
                "3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Å–µ—Ä–≤–∏—Å (Stability AI)"
            )
            
        elif response.status_code == 403:
            await update.message.reply_text(
                "‚ùå –ù–µ—Ç –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –∫ —ç—Ç–æ–π –º–æ–¥–µ–ª–∏!\n\n"
                "–†–µ—à–µ–Ω–∏–µ:\n"
                "1. –ù—É–∂–Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n"
                "2. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å"
            )
            
        else:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {response.status_code}")
            
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")

def main():
    app = Application.builder().token(TELEGRAM_TOKEN).build()
    
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, generate_image))
    app.add_handler(MessageHandler(filters.COMMAND & filters.Regex("start"), start))
    app.add_handler(MessageHandler(filters.COMMAND & filters.Regex("diagnose"), full_hf_diagnosis))
    app.add_handler(MessageHandler(filters.COMMAND & filters.Regex("subscription"), check_subscription_status))
    app.add_handler(MessageHandler(filters.COMMAND & filters.Regex("test_model"), test_simple_model))
    
    RENDER_EXTERNAL_URL = os.getenv("RENDER_EXTERNAL_URL")
    if RENDER_EXTERNAL_URL:
        app.run_webhook(
            listen="0.0.0.0", 
            port=PORT,
            webhook_url=f"{RENDER_EXTERNAL_URL}/webhook",
            url_path="/webhook"
        )
    else:
        app.run_polling()

if __name__ == "__main__":
    main()
